import os
import io
import time
import queue
import json
import base64
import sounddevice as sd
import soundfile as sf
from playsound import playsound
from dotenv import load_dotenv
from utils.bedrock_client import invoke_claude_model
from sarvamai import SarvamAI

load_dotenv()

API_KEY = os.getenv("SARVAM_API_KEY")
if not API_KEY:
    raise ValueError("SARVAM_API_KEY not found in environment.")

client = SarvamAI(api_subscription_key=API_KEY)
SAMPLE_RATE = 16000
CHANNELS = 1
CHUNK_DURATION = 3.5  # seconds

q = queue.Queue()

GREETING_TEMPLATE = {
    "en": "Hello, this is Priya calling on behalf of Zrosis Bank. Am I speaking with Mr. {name}?",
    "hi": "рдирдорд╕реНрддреЗ, рдореИрдВ рдкреНрд░рд┐рдп рд╣реВрдВ рдФрд░ рдЬрд╝реНрд░реЛрд╕рд┐рд╕ рдмреИрдВрдХ рдХреА рдУрд░ рд╕реЗ рдмрд╛рдд рдХрд░ рд░рд╣реА рд╣реВрдВред рдХреНрдпрд╛ рдореИрдВ рд╢реНрд░реА/рд╕реБрд╢реНрд░реА {name} рд╕реЗ рдмрд╛рдд рдХрд░ рд░рд╣реА рд╣реВрдВ?",
    "ta": "ро╡рогроХрпНроХроорпН, роиро╛ройрпН рокро┐ро░ро┐ропро╛. роЗродрпБ ро╕рпНро░рпЛроЪро┐ро╕рпН ро╡роЩрпНроХро┐ропро┐ро▓ро┐ро░рпБроирпНродрпБ роЕро┤рпИрокрпНрокрпБ. родро┐ро░рпБ/родро┐ро░рпБроородро┐ {name} рокрпЗроЪрпБроХро┐ро▒рпАро░рпНроХро│ро╛?",
    "te": "р░╣р░▓р▒Л, р░ир▒Зр░ир▒Б р░кр▒Нр░░р░┐р░п р░ор░╛р░Яр▒Нр░▓р░╛р░бр▒Бр░др▒Бр░ир▒Нр░ир░╛р░ир▒Б, р░Зр░жр░┐ р░Ьр▒Нр░░р▒Лр░╕р░┐р░╕р▒Н р░мр▒Нр░пр░╛р░Вр░Хр▒Н р░ир▒Бр░Вр░бр░┐ р░Хр░╛р░▓р▒Н. р░ор░┐р░╕р▒Нр░Яр░░р▒Н/р░ор░┐р░╕р▒Жр░╕р▒Н {name} р░ор░╛р░Яр▒Нр░▓р░╛р░бр▒Бр░др▒Бр░ир▒Нр░ир░╛р░░р░╛?"
}

EMI_TEMPLATE = {
    "en": "Thank you. IтАЩm reaching out regarding your loan account ending in {loan_id}, which currently shows an outstanding EMI of тВ╣{amount} that was due on {due_date}. If unpaid, it may impact your credit score. We have options such as part payments, revised EMI plans, or deferrals. Would you like help with that or receive a payment link?",
    "hi": "рдзрдиреНрдпрд╡рд╛рджред рдореИрдВ рдЖрдкрдХреЗ рд▓реЛрди рдЦрд╛рддрд╛ рдЬрд┐рд╕рдХреА рд╕рдорд╛рдкреНрддрд┐ {loan_id} рдкрд░ рд╣реЛрддреА рд╣реИ, рдХреЗ рдмрд╛рд░реЗ рдореЗрдВ рд╕рдВрдкрд░реНрдХ рдХрд░ рд░рд╣реА рд╣реВрдВ, рдЬрд┐рд╕рдореЗрдВ тВ╣{amount} рдХреА рдмрдХрд╛рдпрд╛ рдИрдПрдордЖрдИ рд╣реИ рдЬреЛ {due_date} рдХреЛ рджреЗрдп рдереАред рдпрджрд┐ рднреБрдЧрддрд╛рди рдирд╣реАрдВ рдХрд┐рдпрд╛ рдЧрдпрд╛, рддреЛ рдпрд╣ рдЖрдкрдХреЗ рдХреНрд░реЗрдбрд┐рдЯ рд╕реНрдХреЛрд░ рдХреЛ рдкреНрд░рднрд╛рд╡рд┐рдд рдХрд░ рд╕рдХрддрд╛ рд╣реИред рд╣рдорд╛рд░реЗ рдкрд╛рд╕ рдЖрдВрд╢рд┐рдХ рднреБрдЧрддрд╛рди, рд╕рдВрд╢реЛрдзрд┐рдд рдИрдПрдордЖрдИ рдпреЛрдЬрдирд╛рдПрдВ рдпрд╛ рд╕реНрдердЧрди рдЬреИрд╕реЗ рд╡рд┐рдХрд▓реНрдк рд╣реИрдВред рдХреНрдпрд╛ рдЖрдк рд╕рд╣рд╛рдпрддрд╛ рдЪрд╛рд╣рддреЗ рд╣реИрдВ рдпрд╛ рднреБрдЧрддрд╛рди рд▓рд┐рдВрдХ рдкреНрд░рд╛рдкреНрдд рдХрд░рдирд╛ рдЪрд╛рд╣реЗрдВрдЧреЗ?",
    "ta": "роиройрпНро▒ро┐. роЙроЩрпНроХро│рпН роХроЯройрпН роХрогроХрпНроХрпБ {loan_id} роорпБроЯро┐ро╡ро┐ро▓рпН роЗро░рпБрокрпНрокродро╛роХ роЕро▒ро┐ропрокрпНрокроЯрпБроХро┐ройрпНро▒родрпБ, тВ╣{amount} роиро┐ро▓рпБро╡рпИропро┐ро▓рпБро│рпНро│родрпБ рооро▒рпНро▒рпБроорпН {due_date} роЕройрпНро▒рпБ роЪрпЖро▓рпБродрпНрод ро╡рпЗрогрпНроЯро┐ропродрпБ. роЪрпЖро▓рпБродрпНродро╛род роиро┐ро▓рпИропро┐ро▓рпН роЙроЩрпНроХро│рпН роХро┐ро░рпЖроЯро┐роЯрпН ро╕рпНроХрпЛро░рпБроХрпНроХрпБ рокро╛родро┐рокрпНрокрпБ роПро▒рпНрокроЯро▓ро╛роорпН. рокроХрпБродро┐ роХроЯрпНроЯрогроЩрпНроХро│рпН, родро┐ро░рпБродрпНродрокрпНрокроЯрпНроЯ EMI родро┐роЯрпНроЯроЩрпНроХро│рпН роЕро▓рпНро▓родрпБ роТродрпНродро┐ро╡рпИрокрпНрокрпБ роЖроХро┐роп ро╡ро┐ро░рпБрокрпНрокроЩрпНроХро│рпН роОроЩрпНроХро│ро┐роЯроорпН роЙро│рпНро│рой. роирпАроЩрпНроХро│рпН роЙродро╡ро┐ ро╡ро┐ро░рпБроорпНрокрпБроХро┐ро▒рпАро░рпНроХро│ро╛ роЕро▓рпНро▓родрпБ роТро░рпБ роХроЯрпНроЯрог роЗрогрпИрокрпНрокрпБ рокрпЖро▒ ро╡ро┐ро░рпБроорпНрокрпБроХро┐ро▒рпАро░рпНроХро│ро╛?",
    "te": "р░зр░ир▒Нр░пр░╡р░╛р░жр░╛р░▓р▒Б. р░ор▒А р░▓р▒Лр░ир▒Н р░Цр░╛р░др░╛ {loan_id} р░ир▒Бр░Вр░бр░┐ р░ор▒Бр░Чр░┐р░пр░ир▒Бр░Вр░жр░┐, р░Зр░жр░┐ р░кр▒Нр░░р░╕р▒Нр░др▒Бр░др░В тВ╣{amount} р░кр▒Жр░Вр░бр░┐р░Вр░Чр▒Н EMI р░Ър▒Вр░кр░┐р░╕р▒Нр░др▒Бр░Вр░жр░┐, р░Зр░жр░┐ {due_date} р░и due р░Ер░пр░┐р░Вр░жр░┐. р░Ър▒Жр░▓р▒Нр░▓р░┐р░Вр░Ър░ир░┐ р░кр░Хр▒Нр░╖р░Вр░▓р▒Л р░ор▒А р░Хр▒Нр░░р▒Жр░бр░┐р░Яр▒Н р░╕р▒Нр░Хр▒Лр░░р▒Бр░кр▒И р░кр▒Нр░░р░нр░╛р░╡р░В р░Ър▒Вр░кр░╡р░Ър▒Нр░Ър▒Б. р░ор▒Зр░ор▒Б р░нр░╛р░Ч р░Ър▒Жр░▓р▒Нр░▓р░┐р░Вр░кр▒Бр░▓р▒Б, р░╕р░╡р░░р░┐р░╕р▒Нр░др▒Бр░ир▒Нр░и EMI р░кр▒Нр░░р░гр░╛р░│р░┐р░Хр░▓р▒Б р░▓р▒Зр░жр░╛ р░ор░┐р░ир░╣р░╛р░пр░┐р░Вр░кр▒Бр░▓ р░╡р░Вр░Яр░┐ р░Ор░Вр░кр░┐р░Хр░▓р░ир▒Б р░Хр░▓р░┐р░Чр░┐ р░Йр░ир▒Нр░ир░╛р░ор▒Б. р░ор▒Ар░Хр▒Б р░╕р░╣р░╛р░пр░В р░Хр░╛р░╡р░╛р░▓р░╛ р░▓р▒Зр░жр░╛ р░Ър▒Жр░▓р▒Нр░▓р░┐р░Вр░кр▒Б р░▓р░┐р░Вр░Хр▒Н р░Хр░╛р░╡р░╛р░▓р░╛?"
}

# ---------------------- AUDIO UTILITIES ------------------------ #

def record_audio(seconds=CHUNK_DURATION):
    print("ЁЯОЩя╕П Listening... Speak now")
    recording = sd.rec(int(seconds * SAMPLE_RATE), samplerate=SAMPLE_RATE, channels=CHANNELS, dtype='int16')
    sd.wait()
    return recording

def save_wav(array):
    wav_io = io.BytesIO()
    sf.write(wav_io, array, SAMPLE_RATE, format='WAV', subtype='PCM_16')
    wav_io.seek(0)
    return wav_io

def speak(text: str, language_code: str = "unknown", speaker: str = "anushka"):
    print(f"ЁЯФК Speaking ({language_code}): {text}")
    resp = client.text_to_speech.convert(
        text=text,
        target_language_code=language_code,
        model="bulbul:v2",
        speaker=speaker
    )
    audio_b64 = resp.audios[0]
    audio_bytes = base64.b64decode(audio_b64)
    out_path = f"tts_{int(time.time())}.wav"
    with open(out_path, "wb") as f:
        f.write(audio_bytes)
    playsound(out_path)
    os.remove(out_path)

def lang_to_prefix(code):
    if code.startswith("hi"): return "hi"
    if code.startswith("ta"): return "ta"
    if code.startswith("te"): return "te"
    return "en"

# ---------------------- INTERACTION LOOP ------------------------ #

if __name__ == "__main__":
    customer = {
        "name": "Ravi",
        "loan_id": "7824",
        "amount": "4,500",
        "due_date": "25 July"
    }

    # 1. Initial generic English greeting
    speak("Hello. Please respond to continue.", language_code="en-IN")

    # 2. Wait for their response (to detect language)
    user_audio = record_audio()
    wav_io = save_wav(user_audio)

    # 3. Transcribe and detect language
    resp = client.speech_to_text.transcribe(
        file=("input.wav", wav_io, "audio/wav"),
        model="saarika:v2.5",
        language_code="unknown"
    )
    user_text = resp.transcript
    lang_code = resp.language_code or "en-IN"
    lang_key = lang_to_prefix(lang_code)
    print(f"ЁЯза Transcript: {user_text} ({lang_code})")

    # 4. Greet in detected language
    greeting = GREETING_TEMPLATE.get(lang_key, GREETING_TEMPLATE["en"]).format(name=customer['name'])
    speak(greeting, language_code=lang_code)

    # 5. Wait for confirmation response
    user_audio = record_audio()
    wav_io = save_wav(user_audio)
    resp = client.speech_to_text.transcribe(
        file=("input.wav", wav_io, "audio/wav"),
        model="saarika:v2.5",
        language_code=lang_code
    )
    user_text = resp.transcript

    # 6. Send to Bedrock
    prompt = [
        {"sender": "user", "content": user_text},
        {"sender": "assistant", "content": EMI_TEMPLATE.get(lang_key, EMI_TEMPLATE["en"]).format(**customer)}
    ]
    messages = []
    for m in prompt:
        messages.append({
            "role": "user" if m['sender'] == "user" else "assistant",
            "content": [{"type": "text", "text": m['content']}]
        })

    reply = invoke_claude_model(messages)
    if not reply.strip():
        reply = EMI_TEMPLATE.get(lang_key, EMI_TEMPLATE["en"]).format(**customer)

    # 7. Speak reply in detected language
    speak(reply, language_code=lang_code)
    print("тЬЕ Interaction complete.")
import os
import requests
from dotenv import load_dotenv
from fastapi import FastAPI, WebSocket

# Load secrets from .env
load_dotenv()

EXOTEL_SID = os.getenv("EXOTEL_SID")
EXOTEL_API_TOKEN = os.getenv("EXOTEL_API_TOKEN")
EXOPHONE = os.getenv("EXOPHONE")
EXOTEL_APP_ID = os.getenv("EXOTEL_APP_ID")

app = FastAPI()

def trigger_exotel_call(to_number: str):
    url = f"https://{EXOTEL_API_Key}:{EXOTEL_API_TOKEN}@api.exotel.com/v1/Accounts/{EXOTEL_SID}/Calls/connect.json"
    # https://<your_api_key>:<your_api_token><subdomain>/v1/Accounts/<your_sid>/Calls/connect

    payload = {
        'From': to_number,
        'CallerId': EXOPHONE,
        'Url': f"http://my.exotel.com/{EXOTEL_SID}/exoml/start_voice/{EXOTEL_APP_ID}",
        'CallType': 'trans',
        'TimeLimit': '300',
        'TimeOut': '30',
        'CustomField': 'Zrosis_Call_01'
    }

    response = requests.post(url, data=payload)
    if response.status_code == 200:
        print("тЬЕ Exotel call triggered:", response.json())
    else:
        print("тЭМ Failed to trigger Exotel call:", response.status_code, response.text)

@app.websocket("/ws")
async def websocket_endpoint(websocket: WebSocket):
    await websocket.accept()
    while True:
        data = await websocket.receive_text()
        if data == "trigger-call":
            print("ЁЯУЮ Triggering Exotel call...")
            trigger_exotel_call("7417119104")  # Target number
            await websocket.send_text("ЁЯУЮ Call triggered successfully")
